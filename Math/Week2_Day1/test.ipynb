{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv('Elec_Demand_train.csv')[:1000]\n",
    "\n",
    "demand_set = data.iloc[:, 1].values\n",
    "date_set = data.iloc[:, 0].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(demand_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "hours = [index % 24 for index, _ in enumerate(date_set)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(940, 60, 1)\n",
      "(940, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "demand_X = []\n",
    "hour_X = []\n",
    "y = []\n",
    "\n",
    "for i in range(60, len(demand_set)):\n",
    "    demand_X.append(training_set_scaled[i-60:i])\n",
    "    hour_X.append(hours[i-60:i])\n",
    "    y.append(training_set_scaled[i, 0])\n",
    "\n",
    "demand_X, hour_X, y = np.array(demand_X), np.array(hour_X), np.array(y)\n",
    "hour_X = np.reshape(hour_X, (hour_X.shape[0], hour_X.shape[1], 1))\n",
    "print(demand_X.shape)\n",
    "print(hour_X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 0.2909783 ],\n        [ 0.25874636],\n        [ 0.23769031],\n        ...,\n        [ 9.        ],\n        [10.        ],\n        [11.        ]],\n\n       [[ 0.25874636],\n        [ 0.23769031],\n        [ 0.23955296],\n        ...,\n        [10.        ],\n        [11.        ],\n        [12.        ]],\n\n       [[ 0.23769031],\n        [ 0.23955296],\n        [ 0.24481697],\n        ...,\n        [11.        ],\n        [12.        ],\n        [13.        ]],\n\n       ...,\n\n       [[ 0.33422417],\n        [ 0.30774214],\n        [ 0.29462261],\n        ...,\n        [10.        ],\n        [11.        ],\n        [12.        ]],\n\n       [[ 0.30774214],\n        [ 0.29462261],\n        [ 0.31689342],\n        ...,\n        [11.        ],\n        [12.        ],\n        [13.        ]],\n\n       [[ 0.29462261],\n        [ 0.31689342],\n        [ 0.3819242 ],\n        ...,\n        [12.        ],\n        [13.        ],\n        [14.        ]]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_hours_X = np.hstack((demand_X, hour_X))\n",
    "demand_hours_X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(demand_X, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 20:48:40.218529: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-18 20:48:40.219289: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "my_regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "my_regressor.add(LSTM(units = 30, return_sequences = True,\n",
    "                      input_shape = (demand_X.shape[1], 1)))\n",
    "my_regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "#my_regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "#my_regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "#my_regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "#my_regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "my_regressor.add(LSTM(units = 30))\n",
    "my_regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "my_regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "my_regressor.compile(optimizer = 'adam', loss = 'mean_squared_error',\n",
    "                     metrics = ['mean_squared_error'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 20:48:53.019992: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 20:48:53.760563: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-18 20:48:53.994323: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-18 20:48:54.112271: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-18 20:48:54.249512: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-18 20:48:54.441181: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.1632 - mean_squared_error: 0.1632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 20:48:55.764396: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-18 20:48:55.842445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-18 20:48:55.921027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 104ms/step - loss: 0.1632 - mean_squared_error: 0.1632 - val_loss: 0.0747 - val_mean_squared_error: 0.0747\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0453 - mean_squared_error: 0.0453 - val_loss: 0.0336 - val_mean_squared_error: 0.0336\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0320 - val_mean_squared_error: 0.0320\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0652 - mean_squared_error: 0.0652 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0848 - mean_squared_error: 0.0848 - val_loss: 0.0527 - val_mean_squared_error: 0.0527\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0778 - mean_squared_error: 0.0778 - val_loss: 0.0576 - val_mean_squared_error: 0.0576\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0748 - mean_squared_error: 0.0748 - val_loss: 0.0592 - val_mean_squared_error: 0.0592\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0756 - mean_squared_error: 0.0756 - val_loss: 0.0578 - val_mean_squared_error: 0.0578\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0691 - mean_squared_error: 0.0691 - val_loss: 0.0595 - val_mean_squared_error: 0.0595\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0658 - mean_squared_error: 0.0658 - val_loss: 0.0623 - val_mean_squared_error: 0.0623\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0684 - mean_squared_error: 0.0684 - val_loss: 0.0638 - val_mean_squared_error: 0.0638\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0654 - mean_squared_error: 0.0654 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0618 - mean_squared_error: 0.0618 - val_loss: 0.0580 - val_mean_squared_error: 0.0580\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0554 - mean_squared_error: 0.0554 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0563 - mean_squared_error: 0.0563 - val_loss: 0.0576 - val_mean_squared_error: 0.0576\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0554 - mean_squared_error: 0.0554 - val_loss: 0.0582 - val_mean_squared_error: 0.0582\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0588 - mean_squared_error: 0.0588 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0577 - mean_squared_error: 0.0577 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0597 - mean_squared_error: 0.0597 - val_loss: 0.0589 - val_mean_squared_error: 0.0589\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0563 - mean_squared_error: 0.0563 - val_loss: 0.0637 - val_mean_squared_error: 0.0637\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0556 - mean_squared_error: 0.0556 - val_loss: 0.0589 - val_mean_squared_error: 0.0589\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0519 - mean_squared_error: 0.0519 - val_loss: 0.0594 - val_mean_squared_error: 0.0594\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0521 - mean_squared_error: 0.0521 - val_loss: 0.0588 - val_mean_squared_error: 0.0588\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0537 - mean_squared_error: 0.0537 - val_loss: 0.0591 - val_mean_squared_error: 0.0591\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0533 - mean_squared_error: 0.0533 - val_loss: 0.0590 - val_mean_squared_error: 0.0590\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0540 - mean_squared_error: 0.0540 - val_loss: 0.0588 - val_mean_squared_error: 0.0588\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0509 - mean_squared_error: 0.0509 - val_loss: 0.0595 - val_mean_squared_error: 0.0595\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0495 - mean_squared_error: 0.0495 - val_loss: 0.0590 - val_mean_squared_error: 0.0590\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0499 - mean_squared_error: 0.0499 - val_loss: 0.0591 - val_mean_squared_error: 0.0591\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0523 - mean_squared_error: 0.0523 - val_loss: 0.0589 - val_mean_squared_error: 0.0589\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0511 - mean_squared_error: 0.0511 - val_loss: 0.0586 - val_mean_squared_error: 0.0586\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0507 - mean_squared_error: 0.0507 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0507 - mean_squared_error: 0.0507 - val_loss: 0.0593 - val_mean_squared_error: 0.0593\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0511 - mean_squared_error: 0.0511 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0497 - mean_squared_error: 0.0497 - val_loss: 0.0589 - val_mean_squared_error: 0.0589\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0519 - mean_squared_error: 0.0519 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0484 - mean_squared_error: 0.0484 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0493 - mean_squared_error: 0.0493 - val_loss: 0.0588 - val_mean_squared_error: 0.0588\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0500 - mean_squared_error: 0.0500 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0501 - mean_squared_error: 0.0501 - val_loss: 0.0594 - val_mean_squared_error: 0.0594\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0476 - mean_squared_error: 0.0476 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0501 - mean_squared_error: 0.0501 - val_loss: 0.0586 - val_mean_squared_error: 0.0586\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0493 - mean_squared_error: 0.0493 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0490 - mean_squared_error: 0.0490 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0500 - mean_squared_error: 0.0500 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0487 - mean_squared_error: 0.0487 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0518 - mean_squared_error: 0.0518 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0488 - mean_squared_error: 0.0488 - val_loss: 0.0586 - val_mean_squared_error: 0.0586\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0495 - mean_squared_error: 0.0495 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0490 - mean_squared_error: 0.0490 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0484 - mean_squared_error: 0.0484 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0490 - mean_squared_error: 0.0490 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0491 - mean_squared_error: 0.0491 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0486 - mean_squared_error: 0.0486 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.0493 - mean_squared_error: 0.0493 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.0504 - mean_squared_error: 0.0504 - val_loss: 0.0588 - val_mean_squared_error: 0.0588\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0488 - mean_squared_error: 0.0488 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0487 - mean_squared_error: 0.0487 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0490 - mean_squared_error: 0.0490 - val_loss: 0.0587 - val_mean_squared_error: 0.0587\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0486 - mean_squared_error: 0.0486 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0481 - mean_squared_error: 0.0481 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0485 - mean_squared_error: 0.0485 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0475 - mean_squared_error: 0.0475 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0476 - mean_squared_error: 0.0476 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0495 - mean_squared_error: 0.0495 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0488 - mean_squared_error: 0.0488 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0469 - mean_squared_error: 0.0469 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0483 - mean_squared_error: 0.0483 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0504 - mean_squared_error: 0.0504 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0499 - mean_squared_error: 0.0499 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0493 - mean_squared_error: 0.0493 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0501 - mean_squared_error: 0.0501 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0478 - mean_squared_error: 0.0478 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.0490 - mean_squared_error: 0.0490 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0489 - mean_squared_error: 0.0489 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0484 - mean_squared_error: 0.0484 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0479 - mean_squared_error: 0.0479 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0489 - mean_squared_error: 0.0489 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0480 - mean_squared_error: 0.0480 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0468 - mean_squared_error: 0.0468 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0500 - mean_squared_error: 0.0500 - val_loss: 0.0582 - val_mean_squared_error: 0.0582\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0486 - mean_squared_error: 0.0486 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0486 - mean_squared_error: 0.0486 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.0484 - mean_squared_error: 0.0484 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0481 - mean_squared_error: 0.0481 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0487 - mean_squared_error: 0.0487 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0475 - mean_squared_error: 0.0475 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0474 - mean_squared_error: 0.0474 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0470 - mean_squared_error: 0.0470 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0461 - mean_squared_error: 0.0461 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0475 - mean_squared_error: 0.0475 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0479 - mean_squared_error: 0.0479 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0482 - mean_squared_error: 0.0482 - val_loss: 0.0585 - val_mean_squared_error: 0.0585\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0483 - mean_squared_error: 0.0483 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0582 - val_mean_squared_error: 0.0582\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0480 - mean_squared_error: 0.0480 - val_loss: 0.0582 - val_mean_squared_error: 0.0582\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0478 - mean_squared_error: 0.0478 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0471 - mean_squared_error: 0.0471 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0484 - mean_squared_error: 0.0484 - val_loss: 0.0582 - val_mean_squared_error: 0.0582\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0582 - val_mean_squared_error: 0.0582\n"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "history = my_regressor.fit(X_train,\n",
    "                           y_train,\n",
    "                           validation_split=0.2,\n",
    "                           epochs = 100,\n",
    "                           batch_size = 32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 20:51:57.197738: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-18 20:51:57.261193: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-18 20:51:57.338142: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred_demand = my_regressor.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.17847140606453804"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_absolute_error(y_test, y_pred_demand)\n",
    "mse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(demand_hours_X, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "my_regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "my_regressor.add(LSTM(units = 30, return_sequences = True,\n",
    "                      input_shape = (demand_X.shape[1], 1)))\n",
    "my_regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "#my_regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "#my_regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "#my_regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "#my_regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "my_regressor.add(LSTM(units = 30))\n",
    "my_regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "my_regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "my_regressor.compile(optimizer = 'adam', loss = 'mean_squared_error',\n",
    "                     metrics = ['mean_squared_error'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 60, 2), found shape=(None, 120, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/cj/7pbw4t016v72qg78txbzq1b40000gn/T/ipykernel_32000/2057371664.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Fitting the RNN to the Training set\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m history = my_regressor.fit(X_train,\n\u001B[0m\u001B[1;32m      3\u001B[0m                            \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m                            \u001B[0mvalidation_split\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m                            \u001B[0mepochs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/globalenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mautograph_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1127\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1128\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1129\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1130\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1131\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 60, 2), found shape=(None, 120, 1)\n"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "history = my_regressor.fit(X_train,\n",
    "                           y_train,\n",
    "                           validation_split=0.2,\n",
    "                           epochs = 100,\n",
    "                           batch_size = 32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 60, 1), found shape=(None, 120, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/cj/7pbw4t016v72qg78txbzq1b40000gn/T/ipykernel_32000/1704859891.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0my_pred_demand\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmy_regressor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/globalenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mautograph_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1127\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1128\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1129\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1130\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1131\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/daniyarkurmanbayev/miniforge3/envs/globalenv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 60, 1), found shape=(None, 120, 1)\n"
     ]
    }
   ],
   "source": [
    "y_pred_demand = my_regressor.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.17847140606453804"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_absolute_error(y_test, y_pred_demand)\n",
    "mse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}